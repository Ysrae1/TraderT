{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import pdb\n",
    "import time\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "_dtype_ = torch.float32\n",
    "_device_ = torch.device('mps')\n",
    "\n",
    "# seq_len = 1\n",
    "# seq_len_forward = 1\n",
    "\n",
    "class PP_MLP(nn.Module): # Price Pridiction\n",
    "\n",
    "    def __init__(self, seq_len_f):\n",
    "\n",
    "        super(PP_MLP, self).__init__() \n",
    "        self.layer1 = nn.Linear(14, 20)  \n",
    "        self.layer2 = nn.Linear(20, 20)\n",
    "        self.layer3 = nn.Linear(20, 20)\n",
    "        self.output = nn.Linear(20, seq_len_f)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.relu(self.layer1(x)) \n",
    "        x = self.relu(self.layer2(x)) \n",
    "        x = self.relu(self.layer3(x)) \n",
    "        return self.output(x) \n",
    "    \n",
    "class PP_LSTM(nn.Module):\n",
    "    def __init__(self, seq_len_f):\n",
    "\n",
    "        super(PP_LSTM, self).__init__()\n",
    "        self.hidden_dim = 20\n",
    "        self.lstm = nn.LSTM(14, self.hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.dense_1 = nn.Linear(self.hidden_dim, 20)\n",
    "        self.dense_2 = nn.Linear(20, 20)\n",
    "        self.dense_3 = nn.Linear(20, seq_len_f)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        x = lstm_out[:, -1, :]\n",
    "        x = self.dropout(x) \n",
    "        x = self.relu(self.dense_1(x))\n",
    "        x = self.relu(self.dense_2(x))\n",
    "        x = self.dense_3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class PP_LSTMSeq2Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(PP_LSTMSeq2Seq, self).__init__()\n",
    "\n",
    "        emb_size = 64\n",
    "\n",
    "        self.embedding_encoder = nn.Linear(14, emb_size)\n",
    "        self.embedding_decoder = nn.Linear(1, emb_size)\n",
    "\n",
    "        self.mlp_emb = nn.Sequential(\n",
    "            nn.Linear(emb_size, emb_size),\n",
    "            nn.LayerNorm(emb_size),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(emb_size, emb_size)\n",
    "        )\n",
    "\n",
    "        self.hidden_dim = 20\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=emb_size,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=0.25\n",
    "        )\n",
    "\n",
    "        self.dense_1 = nn.Linear(self.hidden_dim, 10)\n",
    "        self.dense_2 = nn.Linear(10, 5)\n",
    "        self.dense_3 = nn.Linear(5, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if x.shape[-1] == 1:\n",
    "            x = self.embedding_decoder(x)\n",
    "        else:\n",
    "            x = self.embedding_encoder(x)\n",
    "        \n",
    "        x = self.mlp_emb(x)\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "\n",
    "        x = lstm_out#[:, -1, :]\n",
    "        x = self.relu(self.dense_1(x))\n",
    "        x = self.relu(self.dense_2(x))\n",
    "        x = self.dense_3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Components of transformer\n",
    "\n",
    "class SinPosEncoding(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.emb_dim // 2\n",
    "        pos_emb = np.log(10000) / (half_dim - 1)\n",
    "        pos_emb = torch.exp(torch.arange(half_dim, device = device) * (- pos_emb))\n",
    "        pos_emb = x[:, None] * pos_emb[None, :]\n",
    "        pos_emb = torch.cat((pos_emb.sin(), pos_emb.cos()), dim = -1)\n",
    "        return pos_emb\n",
    "    \n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 hidden_size = 64, \n",
    "                 num_heads = 4, \n",
    "                 masking = True):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.masking = masking\n",
    "        self.mh_attn = nn.MultiheadAttention(hidden_size,\n",
    "                                             num_heads = num_heads,\n",
    "                                             batch_first = True,\n",
    "                                             dropout = 0.25)\n",
    "\n",
    "    def forward(self, \n",
    "                x_in, \n",
    "                kv_in, \n",
    "                key_mask = None):\n",
    "        \n",
    "        if self.masking:\n",
    "            bs, l, h = x_in.shape\n",
    "            mask = torch.triu(torch.ones(l, l, device=x_in.device), 1).bool()\n",
    "        else:\n",
    "            mask = None\n",
    "\n",
    "        return self.mh_attn(x_in, \n",
    "                            kv_in, \n",
    "                            kv_in, \n",
    "                            attn_mask = mask, \n",
    "                            key_padding_mask = key_mask)[0]\n",
    "\n",
    "class CoreLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 hidden_size = 64, \n",
    "                 num_heads = 4, \n",
    "                 block_type = 'encoder', \n",
    "                 masking = True):\n",
    "        super().__init__()\n",
    "        self.block_type = block_type\n",
    "\n",
    "        self.layer_norm_1 = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        self.attn_1 = AttentionLayer(hidden_size = hidden_size, \n",
    "                                     num_heads = num_heads, \n",
    "                                     masking = masking)\n",
    "        \n",
    "        if self.block_type == 'decoder':\n",
    "            self.layer_norm_2 = nn.LayerNorm(hidden_size)\n",
    "            self.attn_2 = AttentionLayer(hidden_size = hidden_size, \n",
    "                                         num_heads = num_heads, \n",
    "                                         masking = False)\n",
    "        \n",
    "        self.layer_norm_mlp = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(hidden_size, hidden_size * 4),\n",
    "                                 nn.ELU(),\n",
    "                                 nn.Linear(hidden_size * 4, hidden_size))\n",
    "                \n",
    "    def forward(self,\n",
    "                x, \n",
    "                input_key_mask = None, \n",
    "                cross_key_mask = None, \n",
    "                kv_cross = None):\n",
    "\n",
    "        x = self.attn_1(x, x, key_mask = input_key_mask) + x\n",
    "        x = self.layer_norm_1(x)\n",
    "\n",
    "        if self.block_type == 'decoder':\n",
    "            x = self.attn_2(x, kv_cross, key_mask = cross_key_mask) + x\n",
    "            x = self.layer_norm_2(x)\n",
    "\n",
    "        x = self.mlp(x) + x\n",
    "        return self.layer_norm_mlp(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 dim_i, \n",
    "                 hidden_size = 64, \n",
    "                 num_layers = 2, \n",
    "                 num_heads = 4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Linear(dim_i, hidden_size)\n",
    "        # Instantiate the positional encoding\n",
    "        self.pos_encoding = SinPosEncoding(hidden_size)\n",
    "\n",
    "        self.core_layer = nn.ModuleList([\n",
    "            CoreLayer(hidden_size, \n",
    "                      num_heads, \n",
    "                      'encoder', \n",
    "                      masking = False) for _ in range(num_layers)\n",
    "        ])\n",
    "                \n",
    "    def forward(self, \n",
    "                input_seq, \n",
    "                padding_mask = None):        \n",
    "        \n",
    "        input_embs = self.embedding(input_seq)\n",
    "        bs, l, h = input_embs.shape\n",
    "\n",
    "        indices = torch.arange(l, device = input_seq.device)\n",
    "        pos_encoding = self.pos_encoding(indices).reshape(1, l, h).expand(bs, l, h)\n",
    "        embs = input_embs + pos_encoding\n",
    "        \n",
    "        for layer in self.core_layer:\n",
    "            embs = layer(embs, \n",
    "                         input_key_mask = padding_mask)\n",
    "        \n",
    "        return embs\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 dim_o, \n",
    "                 hidden_size = 64, \n",
    "                 num_layers = 2, \n",
    "                 num_heads = 4,\n",
    "                 categorical = False):\n",
    "        super().__init__()\n",
    "\n",
    "        if categorical:\n",
    "            self.embedding = nn.Embedding(dim_o, hidden_size)\n",
    "            self.embedding.weight.data = 0.001 * self.embedding.weight.data\n",
    "        else:\n",
    "            self.embedding = nn.Linear(dim_o, hidden_size)\n",
    "\n",
    "        self.pos_encoding = SinPosEncoding(hidden_size)\n",
    "        \n",
    "        self.core_layer = nn.ModuleList([\n",
    "            CoreLayer(hidden_size, \n",
    "                      num_heads, \n",
    "                      'decoder', \n",
    "                      masking = True) for _ in range(num_layers)\n",
    "        ])\n",
    "                \n",
    "        self.fc_out = nn.Linear(hidden_size, dim_o)\n",
    "        \n",
    "    def forward(self, \n",
    "                input_seq, \n",
    "                encoder_output, \n",
    "                input_padding_mask = None, \n",
    "                encoder_padding_mask = None):\n",
    "\n",
    "        input_embs = self.embedding(input_seq)\n",
    "\n",
    "        bs, l, h = input_embs.shape\n",
    "\n",
    "        seq_index = torch.arange(l, device = input_seq.device)\n",
    "        pos_encoding = self.pos_encoding(seq_index).reshape(1, l, h).expand(bs, l, h)\n",
    "        embs = input_embs + pos_encoding\n",
    "        \n",
    "        for layer in self.core_layer:\n",
    "            embs = layer(embs,\n",
    "                         input_key_mask = input_padding_mask,\n",
    "                         cross_key_mask = encoder_padding_mask, \n",
    "                         kv_cross = encoder_output)\n",
    "        \n",
    "        return self.fc_out(embs)\n",
    "    \n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 hidden_size = 64, \n",
    "                 num_layers = (2,2), \n",
    "                 num_heads = 4,\n",
    "                 categorical = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(dim_i=14, \n",
    "                               hidden_size = hidden_size, \n",
    "                               num_layers = num_layers[0], \n",
    "                               num_heads = num_heads,)\n",
    "        \n",
    "        self.decoder = Decoder(dim_o = 1, \n",
    "                               hidden_size = hidden_size, \n",
    "                               num_layers = num_layers[1], \n",
    "                               num_heads = num_heads,\n",
    "                               categorical = categorical)\n",
    "\n",
    "    def forward(self, input_seq, target_seq):\n",
    "        \n",
    "        # input_key_mask = input_seq == 0\n",
    "        input_key_mask = None\n",
    "        # output_key_mask = target_seq == 0\n",
    "        output_key_mask = None\n",
    "        \n",
    "        encoder_output = self.encoder(input_seq = input_seq,\n",
    "                                      padding_mask = input_key_mask)\n",
    "        \n",
    "        decoder_output = self.decoder(input_seq = target_seq,\n",
    "                                      encoder_output = encoder_output,\n",
    "                                      input_padding_mask = output_key_mask,\n",
    "                                      encoder_padding_mask = input_key_mask)\n",
    "\n",
    "        return decoder_output\n",
    "    \n",
    "class H5Dataset(Dataset):\n",
    "    def __init__(self, file_path, norm_flag):\n",
    "        self.file_path = file_path\n",
    "        self.dataset = {}\n",
    "\n",
    "        with h5py.File(self.file_path, 'r') as file:\n",
    "            self.dataset['inputs'] = file['inputs'][:]\n",
    "            self.dataset['outputs'] = file['outputs'][:]\n",
    "            \n",
    "\n",
    "        if norm_flag == 'n':\n",
    "            self.normalization()\n",
    "        if norm_flag == 'd':\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset['inputs'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_data = torch.tensor(self.dataset['inputs'][idx], dtype=torch.float32)\n",
    "        output_data = torch.tensor(self.dataset['outputs'][idx], dtype=torch.float32)\n",
    "        return input_data, output_data\n",
    "    \n",
    "    def normalization(self):\n",
    "        inputs = self.dataset['inputs']\n",
    "        outputs = self.dataset['outputs']\n",
    "        min_vals_i = inputs.min(axis=0)  \n",
    "        max_vals_i = inputs.max(axis=0)\n",
    "        if outputs.ndim != 1:\n",
    "            min_vals_o = np.min(outputs)  \n",
    "            max_vals_o = np.max(outputs)   \n",
    "        else:\n",
    "            min_vals_o = outputs.min(axis=0)  \n",
    "            max_vals_o = outputs.max(axis=0)         \n",
    "\n",
    "        ranges_i = max_vals_i - min_vals_i\n",
    "        ranges_i[ranges_i == 0] = 1\n",
    "\n",
    "        if (max_vals_o - min_vals_o)!= 0:\n",
    "            ranges_o = max_vals_o - min_vals_o\n",
    "        else:\n",
    "            ranges_o = 1\n",
    "\n",
    "        self.dataset['inputs'] = (inputs - min_vals_i) / ranges_i\n",
    "        self.dataset['outputs'] = ((outputs - min_vals_o) / ranges_o).squeeze()\n",
    "\n",
    "    def add_SOS(self):\n",
    "        outputs = self.dataset['outputs']\n",
    "        if len(outputs.shape) == 1:\n",
    "            self.dataset['outputs'] = outputs[:,None]\n",
    "\n",
    "        self.dataset['outputs'] = np.concatenate((self.dataset['inputs'][:,-1][:,None],self.dataset['outputs']),axis = -1)\n",
    "\n",
    "\n",
    "    def add_indices(self):\n",
    "        inputs = self.dataset['inputs']\n",
    "        indices = np.arange(inputs.shape[0]).reshape(-1, 1)\n",
    "        self.dataset['inputs'] = np.hstack((indices, inputs))\n",
    "\n",
    "\n",
    "def set_learning_rate(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def denormalize(dataset, model, input):\n",
    "    outputs = dataset.dataset['outputs']\n",
    "    min_vals_o = outputs.min(axis=0)  \n",
    "    max_vals_o = outputs.max(axis=0)         \n",
    "\n",
    "    range_o = max_vals_o - min_vals_o\n",
    "\n",
    "    return (model(input)*range_o)+min_vals_o\n",
    "\n",
    "\n",
    "def seq_gen(dataset, inputs, seq_len, device):\n",
    "\n",
    "    inputs_o = torch.zeros(inputs.shape[0], seq_len, inputs.shape[1]-1)\n",
    "\n",
    "    for i in range(inputs.shape[0]):\n",
    "\n",
    "        idx_i = int(inputs[i][0].item())\n",
    "        start_idx = max(0, idx_i - seq_len + 1)\n",
    "        end_idx = idx_i + 1\n",
    "        segment = dataset.dataset['inputs'][start_idx:end_idx, 1:]\n",
    "\n",
    "        first_col = segment[:, 0]\n",
    "        diff = np.diff(first_col)\n",
    "        last_increasing_idx = np.where(diff <= 0)[0]\n",
    "        if len(last_increasing_idx) > 0:\n",
    "            cut_point = last_increasing_idx[-1] + 1\n",
    "        else:\n",
    "            cut_point = 0\n",
    "\n",
    "        segment[:cut_point, :] = 0\n",
    "\n",
    "        segment_tensor = torch.from_numpy(segment)\n",
    "\n",
    "        fill_start = seq_len - (end_idx - start_idx)\n",
    "\n",
    "        target_size = seq_len - fill_start\n",
    "        \n",
    "        if segment_tensor.shape[0] < target_size:\n",
    "            padding_size = target_size - segment_tensor.shape[0]\n",
    "            padding = torch.zeros(padding_size, segment_tensor.shape[1])\n",
    "            segment_tensor = torch.cat([padding, segment_tensor], dim=0)\n",
    "        \n",
    "        inputs_o[i, fill_start:seq_len, :] = segment_tensor\n",
    "\n",
    "    return inputs_o.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 1\n",
    "seq_len_forward = 1\n",
    "categorical = False\n",
    "\n",
    "dataset_train = H5Dataset(f'../data/lob_data/lob_data_train_f{seq_len_forward}.h5','n')\n",
    "\n",
    "dataset_verif = H5Dataset(f'../data/lob_data/lob_data_verif_f{seq_len_forward}.h5','n')\n",
    "\n",
    "dataset_train.add_SOS()\n",
    "dataset_verif.add_SOS()\n",
    "\n",
    "\n",
    "dataset_train.add_indices()\n",
    "dataset_verif.add_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-This Model has 234625 (approximately 234 kilo) parameters!\n",
      "Start training from scratch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b79bd6c6d78428193aeadfd24a047b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch 1.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df228b8418a4ca8a276d5a63eeb984c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/35141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 1, Batch Loss_train: 0.05056721717119217\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 74\u001b[0m\n\u001b[1;32m     70\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     72\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(PPT_model\u001b[38;5;241m.\u001b[39mparameters(), max_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m---> 74\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m running_loss_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((batch_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m (\u001b[38;5;241m500\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m4096\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mbatch_size)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m batch_idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/MSc_D/env_TraderT/lib/python3.12/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/MSc_D/env_TraderT/lib/python3.12/site-packages/torch/optim/optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/MSc_D/env_TraderT/lib/python3.12/site-packages/torch/optim/adam.py:226\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    214\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    217\u001b[0m         group,\n\u001b[1;32m    218\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m         state_steps,\n\u001b[1;32m    224\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/MSc_D/env_TraderT/lib/python3.12/site-packages/torch/optim/optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MSc_D/env_TraderT/lib/python3.12/site-packages/torch/optim/adam.py:766\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 766\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MSc_D/env_TraderT/lib/python3.12/site-packages/torch/optim/adam.py:380\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    379\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m--> 380\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[1;32m    383\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PPT_model = Transformer(hidden_size = 64,\n",
    "                        num_layers = (2,2),\n",
    "                        num_heads = 4,\n",
    "                        categorical=categorical).to(_device_)\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "loader_train = DataLoader(dataset_train, batch_size = batch_size, shuffle = True)\n",
    "loader_verif = DataLoader(dataset_verif, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(PPT_model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "model_save_path_Transformer = f'PPTS2S_{'cat' if categorical else 'non_cat'}_model_r{seq_len}_f{seq_len_forward}.pt'\n",
    "optimizer_save_path_Transformer = f'PPTS2S_{'cat' if categorical else 'non_cat'}_optimizer_r{seq_len}_f{seq_len_forward}.pt'\n",
    "\n",
    "num_model_params = 0\n",
    "for param in PPT_model.parameters():\n",
    "    num_model_params += param.flatten().shape[0]\n",
    "\n",
    "print(\"-This Model has %d (approximately %d kilo) parameters!\" % (num_model_params, num_model_params//1e3))\n",
    "\n",
    "# Transformer Training using Time Window\n",
    "\n",
    "print(\"Start training from scratch.\")\n",
    "\n",
    "epoch_losses_train = []\n",
    "epoch_losses_verif = []\n",
    "\n",
    "max_epochs = 50\n",
    "\n",
    "patience = 5\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "filename = f'PPTS2S_{'cat' if categorical else 'non_cat'}_r{seq_len}_f{seq_len_forward}_loss_train & verif_{timestamp}.dat'\n",
    "\n",
    "filename_t = f'PPTS2S_{'cat' if categorical else 'non_cat'}_r{seq_len}_f{seq_len_forward}_time_cost_{timestamp}.dat'\n",
    "\n",
    "\n",
    "best_loss_verif = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in trange(0, max_epochs, leave=False, desc=\"Epoch\"):\n",
    "\n",
    "    PPT_model.train()\n",
    "\n",
    "    t_start = time.time()\n",
    "\n",
    "    running_loss_train = 0.0\n",
    "\n",
    "    print(f\"Start epoch {epoch+1}.\\n\")\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(tqdm(loader_train, desc=\"Training\", leave=False)):\n",
    "    # for batch_idx, (inputs, labels) in enumerate(loader_train):\n",
    "        \n",
    "        # if seq_len_forward == 1:\n",
    "        #     inputs, labels = seq_gen(dataset_train, inputs, seq_len, _device_), labels.to(_device_).unsqueeze(1).unsqueeze(2)\n",
    "        # else:\n",
    "        inputs, labels = seq_gen(dataset_train, inputs, seq_len, _device_), labels.to(_device_).unsqueeze(2)\n",
    "\n",
    "        decoder_inputs = labels[:,:-1,:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        decoder_outputs = PPT_model(inputs, decoder_inputs)\n",
    "\n",
    "        loss = criterion(decoder_outputs, labels[:,1:,:])\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(PPT_model.parameters(), max_norm = 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss_train += loss.item()\n",
    "\n",
    "        if ((batch_idx+1) % (500*(4096//batch_size)) == 0) or batch_idx == 0:\n",
    "\n",
    "            print(f\"Epoch {epoch+1}, Batch {batch_idx+1}, Batch Loss_train: {loss.item()}\")\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    PPT_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        running_loss_verif = 0.0\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(tqdm(loader_verif, desc=\"Verification\", leave=False)):\n",
    "        # for batch_idx, (inputs, labels) in enumerate(loader_verif):\n",
    "\n",
    "            # if seq_len_forward == 1:\n",
    "            #     inputs, labels = seq_gen(dataset_verif, inputs, seq_len, _device_), labels.to(_device_).unsqueeze(1).unsqueeze(2)\n",
    "            # else:\n",
    "            inputs, labels = seq_gen(dataset_verif, inputs, seq_len, _device_), labels.to(_device_).unsqueeze(2)\n",
    "\n",
    "            decoder_inputs = labels[:,:-1,:]\n",
    "\n",
    "            decoder_outputs = PPT_model(inputs, decoder_inputs)\n",
    "\n",
    "            loss = criterion(decoder_outputs, labels[:,1:,:])\n",
    "\n",
    "            running_loss_verif += loss.item()\n",
    "\n",
    "    epoch_loss_train = running_loss_train/len(loader_train)\n",
    "    epoch_loss_verif = running_loss_verif/len(loader_verif)\n",
    "\n",
    "    epoch_losses_train.append(epoch_loss_train)\n",
    "    epoch_losses_verif.append(epoch_loss_verif)\n",
    "\n",
    "    # scheduler_step.step()\n",
    "    with open(filename, 'a') as f:\n",
    "\n",
    "        f.write(f'Epoch {epoch+1}, Loss_train: {epoch_loss_train}, Loss_verif: {epoch_loss_verif}\\n')\n",
    "    print(f'Epoch {epoch+1}, Epoch Average Loss_train: {epoch_loss_train}, Epoch Average Loss_verif: {epoch_loss_verif}\\n')\n",
    "\n",
    "    t_end = time.time()\n",
    "    t_duration = t_end - t_start\n",
    "\n",
    "    with open(filename_t,'a') as f_t:\n",
    "        f_t.write(f'Epoch {epoch+1} cost {t_duration} s.\\n')\n",
    "\n",
    "    if epoch_loss_verif < best_loss_verif:\n",
    "        best_loss_verif = epoch_loss_verif\n",
    "        patience_counter = 0\n",
    "        torch.save(PPT_model.state_dict(), model_save_path_Transformer)\n",
    "        torch.save(optimizer.state_dict(), optimizer_save_path_Transformer)\n",
    "    else :\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(f'Early stopping triggered at epoch {epoch+1}')\n",
    "        break\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'r') as file:\n",
    "    loss_conv_f = file.readlines()\n",
    "# Parsing the data to a DataFrame\n",
    "loss_conv = {\n",
    "    'Epoch': [],\n",
    "    'Loss_train': [],\n",
    "    'Loss_verif': []\n",
    "}\n",
    "\n",
    "# Split each line and extract values\n",
    "for line in loss_conv_f:\n",
    "    parts = line.strip().split(', ')\n",
    "    epoch = int(parts[0].split(' ')[1])\n",
    "    loss_train = float(parts[1].split(': ')[1])\n",
    "    loss_verif = float(parts[2].split(': ')[1])\n",
    "    \n",
    "    loss_conv['Epoch'].append(epoch)\n",
    "    loss_conv['Loss_train'].append(loss_train)\n",
    "    loss_conv['Loss_verif'].append(loss_verif)\n",
    "\n",
    "df = pd.DataFrame(loss_conv)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df['Epoch'], df['Loss_train'], label='Loss on Train')\n",
    "plt.plot(df['Epoch'], df['Loss_verif'], label='Loss on Verif')\n",
    "plt.title(f'Loss Convergence Curve - Transformer_Seq2Seq trained with Time Window Length {seq_len} back and {seq_len_forward} forward')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xticks(np.arange(1, 20, 1))\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.ylim(0, max(df['Loss_train']))\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(f'Transformer_S2S Loss Convergence r{seq_len}_f{seq_len_forward}.pdf', format='pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_TraderT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
